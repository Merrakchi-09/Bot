import logging
import traceback
import time
import urllib.parse
import requests
from bs4 import BeautifulSoup
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    ApplicationBuilder, CommandHandler, MessageHandler,
    CallbackQueryHandler, ContextTypes, filters
)

# ===== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª =====
BOT_TOKEN = "Ø¶Ø¹_ØªÙˆÙƒÙ†_Ø§Ù„Ø¨ÙˆØª_Ù‡Ù†Ø§"
AMAZON_TAG = "thehorizon-20"
ALIEXPRESS_TRACKING_ID = "Ewsa6Ro"

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

user_queries = {}

# ===== Ø¯ÙˆØ§Ù„ Ø§Ù„Ø¨ÙˆØª =====
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ğŸ‘‹ Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ! Ø£Ø±Ø³Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†Ù‡.")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.message.text.strip()
    if not query:
        await update.message.reply_text("âŒ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø±Ø³Ø§Ù„ Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­.")
        return

    user_id = update.message.from_user.id
    user_queries[user_id] = query

    buttons = [
        [InlineKeyboardButton("ğŸ”µ Ø£Ù…Ø§Ø²ÙˆÙ†", callback_data="amazon")],
        [InlineKeyboardButton("ğŸ”´ Ø¹Ù„ÙŠ Ø¥ÙƒØ³Ø¨Ø±ÙŠØ³", callback_data="aliexpress")]
    ]
    markup = InlineKeyboardMarkup(buttons)
    await update.message.reply_text("ğŸ” Ø§Ø®ØªØ± Ø§Ù„Ù…Ù†ØµØ© Ù„Ù„Ø¨Ø­Ø« ÙÙŠÙ‡Ø§:", reply_markup=markup)

async def handle_platform_selection(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()

    platform = query.data
    user_id = query.from_user.id
    product = user_queries.get(user_id)

    if not product:
        await query.edit_message_text("âŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØªØ¬ØŒ ÙŠØ±Ø¬Ù‰ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø¥Ø±Ø³Ø§Ù„.")
        return

    await query.edit_message_text(f"â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† \"{product}\" ÙÙŠ {platform.capitalize()}...")

    if platform == "amazon":
        result = search_amazon(product)
    else:
        result = search_aliexpress(product)

    if not result:
        await query.message.reply_text("âŒ Ù„Ù… Ø£Ø¬Ø¯ Ù†ØªØ§Ø¦Ø¬ Ù„Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ø°ÙŠ Ø·Ù„Ø¨ØªÙ‡.")
        return

    title, link = result
    response = f"âœ… <b>{title}</b>\nğŸ”— <a href=\"{link}\">Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù†ØªØ¬</a>"
    await query.message.reply_html(response)

# ===== Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø£Ù…Ø§Ø²ÙˆÙ† =====
def search_amazon(query: str):
    headers = {"User-Agent": "Mozilla/5.0", "Accept-Language": "en-US,en;q=0.9"}
    encoded_query = urllib.parse.quote_plus(query.strip())
    search_url = f"https://www.amazon.com/s?k={encoded_query}"
    try:
        response = requests.get(search_url, headers=headers, timeout=15)
        if response.status_code != 200:
            return f"Ø±Ø§Ø¨Ø· Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† \"{query}\" ÙÙŠ Ø£Ù…Ø§Ø²ÙˆÙ†", f"{search_url}&tag={AMAZON_TAG}"
        soup = BeautifulSoup(response.text, "html.parser")
        results = soup.select('div[data-component-type="s-search-result"]')
        for item in results:
            title_tag = item.select_one("h2 a")
            if not title_tag:
                continue
            title = title_tag.get_text(strip=True)
            raw_link = title_tag.get("href")
            if raw_link and "/dp/" in raw_link:
                asin = raw_link.split("/dp/")[1].split("/")[0].split("?")[0]
                affiliate_link = f"https://www.amazon.com/dp/{asin}?tag={AMAZON_TAG}"
                return title, affiliate_link
        return f"Ø±Ø§Ø¨Ø· Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† \"{query}\" ÙÙŠ Ø£Ù…Ø§Ø²ÙˆÙ†", f"{search_url}&tag={AMAZON_TAG}"
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø£Ù…Ø§Ø²ÙˆÙ†: {e}")
        return None

# ===== Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¹Ù„ÙŠ Ø¥ÙƒØ³Ø¨Ø±ÙŠØ³ =====
def search_aliexpress(query):
    headers = {"User-Agent": "Mozilla/5.0"}
    base_url = "https://www.aliexpress.com/wholesale"
    params = {"SearchText": query}
    search_url = f"{base_url}?{urllib.parse.urlencode(params)}"
    try:
        resp = requests.get(search_url, headers=headers, timeout=15)
        if resp.status_code != 200:
            return None
        soup = BeautifulSoup(resp.text, "html.parser")
        product_link = soup.select_one('a[href*="/item/"]')
        if product_link:
            title = product_link.get_text(strip=True)
            link = product_link['href']
            if link.startswith("//"):
                link = "https:" + link
            elif link.startswith("/"):
                link = "https://www.aliexpress.com" + link
            sep = "&" if "?" in link else "?"
            link += f"{sep}aff_fcid={ALIEXPRESS_TRACKING_ID}"
            return title, link
        search_url += f"&aff_fcid={ALIEXPRESS_TRACKING_ID}"
        return "Ø±Ø§Ø¨Ø· Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¹Ù„ÙŠ Ø¥ÙƒØ³Ø¨Ø±ÙŠØ³", search_url
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø¨Ø¹Ù„ÙŠ Ø¥ÙƒØ³Ø¨Ø±ÙŠØ³: {e}")
        return None

# ===== ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª =====
def run_bot():
    while True:
        try:
            tg_app = ApplicationBuilder().token(BOT_TOKEN).build()
            tg_app.add_handler(CommandHandler("start", start))
            tg_app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
            tg_app.add_handler(CallbackQueryHandler(handle_platform_selection))
            logger.info("âœ… Ø§Ù„Ø¨ÙˆØª ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù†...")
            tg_app.run_polling()
        except Exception:
            logger.error("Ø§Ù„Ø¨ÙˆØª ØªÙˆÙ‚ÙØŒ Ø¬Ø§Ø±ÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„...")
            traceback.print_exc()
            time.sleep(5)

if __name__ == "__main__":
    run_bot()